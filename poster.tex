\input{poster/header.tex}

\title{Machine Learning Enabled Brain Segmentation for Small Animal Neuroimaging Registration}

\author{Hendrik J. Klug$^{1}$,Berkan Lafci$^{2,3}$, Markus Rudin$^{4}$,Daniel Razansky$^{2,3}$, Horea-Ioan Ioanas$^{5}$}
\institute[ETH]{
    $^{1}$ETHZ, Department of Information Technology and Electrical Engineering, Zurich, Switzerland\\
    $^{2}$UZH, Institute of Pharmacology and Toxicology and Institute for Biomedical Engineering, Faculty of Medicine, Zurich, Switzerland\\
    $^{3}$ETHZ, Institute for Biomedical Engineering, Department of Information Technology and Electrical Engineering, Zurich, Switzerland\\
    $^{4}$ETHZ, Center for Imaging Science and Technology, Zurich, Switzerland\\
    $^{5}$Massachusetts Institute of Technology, Department of Biological Engineering, Cambridge, United States of America
}

\date{\today}

\newlength{\columnheight}
\setlength{\columnheight}{0.881\textheight}

\begin{document}
    \begin{frame}
        \vspace{2cm}
        \begin{columns}
            \begin{column}{.42\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.98\textwidth}  % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously
                            \begin{myblock}{Abstract}
                                \input{poster/abstract.tex}
                            \end{myblock}\vfill
                            \vspace{-0.3em}
                            \begin{myblock}{Workflow integration}
                                We lay out a preparatory step to improve brain registration by specifically extracting the brain volume from the MRI scans.
                                \begin{figure}
                                    \centering
                                    \resizebox{0.98\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/masking_graph.py', data = '')}
                                    }
                                    \caption{The novel SAMRI masked workflow takes as input the unprocess BIDS volume as well as the mask and masked volume from the \textcolor{lg}{MLEBE} \cite{mlebe} package.}
                                \end{figure}
%                                \vspace{-0.3em}
                                \begin{figure}
                                    \centering
                                    \resizebox{0.8\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/workflow_graph.py', data = '')}
                                    }
                                    \caption{Flowchart describing the integration of the \textcolor{lg}{MLEBE} \cite{mlebe} package into the \textcolor{lg}{SAMRI} \cite{noauthor_ibt-fmi/samri_2019} Generic workflow.}
                                \end{figure}
                            \end{myblock}\vfill

%                            \vspace{-0.3em}
                            \begin{myblock}{Brain extraction algorithm}
                                \begin{itemize}
                                    \item The brain extraction is done using a trained U-Net \cite{ronneberger_u-net:_2015} which predicts a binary mask over the brain region
                                    \item The training of the brain extraction classifier is done with \textcolor{lg}{SAMRI} preprocessed volumes, using as ground truth the brain template the volumes were mapped onto (\cref{training_graph})
                                    \item Some preprocessing steps were added to create the training dataset:
                                    \begin{itemize}
                                        \item Faulty volumes were manually selected and removed
                                        \item the volumes are normalized and each voxel of the template mask is set to 0 where the voxel value of the volume is 0
                                    \end{itemize}
                                \end{itemize}

                                \begin{figure}
                                    \centering
                                    \resizebox{0.8\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/training_graph.py', data = '')}
                                    }
                                    \caption{Flowchart depicting the training process of the U-Net model.}
                                    \label{training_graph}
                                \end{figure}

                                \begin{figure}
                                    \centering
                                    \begin{subfigure}{0.4\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/unpreprocessed}
                                    \end{subfigure}
%                                    \hfill
                                    \begin{subfigure}{0.4\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/preprocessed}
                                    \end{subfigure}
                                    \caption{Comparison of an unprocessed slice (left) and a preprocessed slice (right) where the volume was normalized and the mask adapted to the volume.}
                                \end{figure}
                            \end{myblock}\vfill





                        }

                    \end{minipage}
                \end{beamercolorbox}
            \end{column}
            \begin{column}{.59\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.98\textwidth} % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously


                            \begin{myblock}{Results}
                                We evaluate the effects of our classifier on a full-fledged registration workflow via the benchmarking algorithms from \cite{ioanas_optimized_2019}.
                                Additionally, we show a qualitative comparison between slice of Volumes registered with our Masked and the Generic workflow in
                                \begin{figure}
%                                    \centering
                                    \includegraphics[width=0.6\textwidth]{data/reg_comp}
                                    \caption{\textbf{The Masked workflow prevents the shifting of outer-brain region voxels into the template-brain region (in blue).} Comparison of slices from 3 different volumes, registered with the Generic (first row) and the Masked (second row) workflow.}
                                \end{figure}

                                \begin{figure}
                                    \includegraphics[width=0.8\textwidth]{data/testset_examples_small}
                                    \caption{\textbf{The Classifier predicts a similar mask to the ground truth.}
                                    Randomly picked plots from the test set illustrate the predictions of the classifier.
                                    The first row presents the input image, the second the ground truth and the third row shows the predictions of the classifier.}
                                \end{figure}


%                                \begin{sansmath}
%                                    \py{pytex_subfigs(
%                                        [
%                                            {'script':'scripts_/vcc_violin.py', 'label':'vccv','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
%                                        'options_pre_caption':'\\vspace{-1.5em}\\',
%                                        'options_post':'\\vspace{1em}',
%                                        'caption':'Comparison of the VCF across workflows and functional contrasts.'
%                                        ,},
%                                            {'script':'scripts_/scf_violin_contrasts.py', 'label':'sccv','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
%                                        'options_pre_caption':'\\vspace{-1.5em}\\',
%                                        'options_post':'\\vspace{1em}',
%                                        'caption':'Comparison of the SCF across workflows and functional contrasts.'
%                                        ,},
%                                            {'script':'scripts_/vc_violin_absdiff.py', 'label':'vcfb','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
%                                        'options_pre_caption':'\\vspace{-1.5em}\\',
%                                        'options_post':'\\vspace{1em}',
%                                        'caption':'Comparison of the distributions of the absolute VCF errors, across workflows and functional contrasts.'
%                                        ,},
%                                            {'script':'scripts_/scf_violin_absdiff.py', 'label':'scfb','conf':'article/1col.conf', 'options_pre':'{.48\\textwidth}',
%                                        'options_pre_caption':'\\vspace{-1.5em}\\',
%                                        'options_post':'\\vspace{1em}',
%                                        'caption':'Comparison of the distributions of the absolute SCF errors, across workflows and functional contrasts.'
%                                        ,},
%                                        ],
%                                        caption='\\textbf{Both the SAMRI Generic and the Masked workflow optimally and reliably conserve volume and smoothness, the latter showing values that are closely distributed to 1.}
%                                        Plots showing the distribution of two target metrics in the first row, together with the respective distributions of the absolute distances to 1 in the second row. Solid lines in the colored distribution densities indicate the sample mean and dashed lines the inner quartiles.
%                                        ',
%                                        label='fig:vc',
%                                        )}
%                                \end{sansmath}
                            \end{myblock}

                            \begin{myblock}{Results and Discussion}
                                \begin{itemize}
                                    \item Adding a brain extraction step to the SAMRI workflow significantly improves registration accuracy as shown with volume conservation and smoothness conservation metrics as well as a qualitative evaluation
                                    \item The brain extraction classifier is trained with data that is preprocessed with the SAMRI registration workflow such that no manual labeling is required.
                                    The classifier can thus be easily be trained further with additional data that can be obtained via the the novel SAMRI Masked workflow
                                    \item The FOSS distribution model for both the classifier and workflow, as well as the article, allows users to easily take advantage of the classifier extendability and recreate the steps described herein
                                    \item We make public the functions used for the masking in the workflow as well as those used to train the classifier, through the \textcolor{mg}{mlebe} python package \cite{mlebe}.

                                \end{itemize}
                            \end{myblock}\vfill

                            \begin{myblock}{References}
                                \vspace{-1em}
                                \begin{multicols}{2}
                                    \scriptsize
                                    \bibliographystyle{ieeetr}
                                    \bibliography{./bib}
                                \end{multicols}
                                \vspace{-1em}
                            \end{myblock}\vfill


                        }
                    \end{minipage}
                \end{beamercolorbox}
            \end{column}

        \end{columns}
    \end{frame}
\end{document}
