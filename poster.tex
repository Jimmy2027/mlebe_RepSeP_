\input{poster/header.tex}

\title{Machine Learning Enabled Brain Segmentation for Small Animal Neuroimaging Registration}

\author{Hendrik J. Klug$^{1,2}$,Berkan Lafci$^{2}$,Zhiva Skachokova$^{2}$, Markus Rudin$^{2}$,Daniel Razansky$^{2}$, Horea-Ioan Ioanas$^{2,3}$}
\institute[ETH]{
    $^{1}$Department of Information Technology and Electrical Engineering, ETH Zurich, Switzerland\\
    $^{2}$Institute for Biomedical Engineering, ETH and University of Zurich, Switzerland\\
    $^{3}$Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, United States of America
}

\date{\today}

\newlength{\columnheight}
\setlength{\columnheight}{0.881\textheight}

\begin{document}
    \begin{frame}
        \vspace{2cm}
        \begin{columns}
            \begin{column}{.42\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.98\textwidth}  % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously
                            \begin{myblock}{Abstract}
                                \input{poster/abstract.tex}
                            \end{myblock}\vfill

                            \begin{myblock}{Objectives}
                                \begin{itemize}
                                    \item Develop a brain extraction framework based on “imperfect prior” data from a registration workflow which provides medium-accuracy registration without employing brain extraction.
                                    \item Analyze classification performance.
                                    \item Integrate this framework into a state-of-the-art small animal registration workflow \cite{irsabi}.
                                    \item Verify whether pre-registration brain extraction improves the overall registration quality of the workflow.
                                \end{itemize}
                            \end{myblock}

                            \begin{myblock}{Workflow Integration}
                                \vspace{-1.6em}
                                \begin{figure}
                                    \centering
                                    \includedot[width=\textwidth]{data/poster/masked_nipype}
                                    \vspace{-2.9em}
                                    \caption{
                                        “SAMRI Generic Masked” workflow, a variant of the “SAMRI Generic” workflow \cite{irsabi}, which includes two additional nodes (shown in blue) providing the workflow with both the masked data and the binary mask as produced by the \textcolor{lg}{MLEBE} \cite{mlebe} brain extraction framework developed for this study.
                                    }
                                    \label{masked_worklfow_graph}
                                \end{figure}

                                \vspace{-0.8em}

                                \begin{figure}
                                    \centering
                                    \resizebox{0.9\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/masking_graph.py', data = '')}
                                    }
                                    \caption{
                                        The \textcolor{lg}{MLEBE} package takes as input the unprocessed data and produces as outputs the masked data and with the binary mask.
                                        Both are used to restrict the similarity metric computation area in the “SAMRI Generic Masked” workflow, derived from the \textcolor{lg}{SAMRI} \cite{irsabi} package.
                                    }
                                \end{figure}
%%                                \vspace{-0.3em}
%                                \begin{figure}
%                                    \centering
%                                    \resizebox{0.4\textwidth}{!}{%
%                                        \py{pytex_printonly(script='scripts_/graphs/workflow_graph.py', data = '')}
%                                    }
%                                    \caption{Flowchart describing the integration of the \textcolor{lg}{MLEBE} \cite{mlebe} package into the \textcolor{lg}{SAMRI} \cite{noauthor_ibt-fmi/samri_2019} Generic workflow.}
%                                \end{figure}
                            \end{myblock}\vfill

%                            \vspace{-0.3em}
                            \begin{myblock}{Brain extraction framework}
                                \begin{itemize}
                                    \item The brain tissue classification is performed via a trained 3D U-Net \cite{ronneberger_u-net:_2015}.
                                    \item The training dataset consists of priors obtained from the “SAMRI Generic” workflow \textcolor{lg}{SAMRI} \cite{irsabi}, which registers unmasked brain scans to a template.
                                    \item Some data optimization steps were added to create the training dataset:
                                    \begin{itemize}
                                        \item Expert operators blacklisted inaccurate registration results.
                                        \item The transformed data was normalized (substracting the whole image mean and dividing by the standard deviation, \cref{preprocessing_xample}).
                                        \item Annotations extending beyond the experimental data range were set to non-brain i.e. 0 (\cref{preprocessing_xample}).
                                        \item Some random transformations were performed to augment the data --- e.g. rotations of up to 20$^{\circ}$, random bias field addition, and horizontal as well as vertical flips.
                                    \end{itemize}
                                \end{itemize}

%                                \vspace{1em}

                                \begin{figure}
                                    \centering
                                    \resizebox{0.98\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/training_graph.py', data = '')}
                                    }
                                    \vspace{0.5em}
                                    \caption{
                                        Flowchart depicting the training process of the U-Net model. Outside the blue box are the processing steps that map the data to the template reference space (i.e. create the training dataset)
                                        Inside the blue box are the training steps of the U-Net model.
                                        The model predicts a mask for each preprocessed input 3D image, which is then compared to the template mask using the Dice score. The parameters of the model are then updated such that the Dice score is maximized.
                                    }
                                    \label{training_graph}
                                \end{figure}

                                \vspace{-0.5em}

                                \begin{figure}
                                    \centering
                                    \begin{subfigure}{0.25\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/unpreprocessed}
                                    \end{subfigure}
                                    \hspace{2em}
                                    \begin{subfigure}{0.25\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/preprocessed}
                                    \end{subfigure}
                                    \vspace{-0.5em}
                                    \caption{Comparison of an unprocessed slice (left) and a preprocessed slice (right) where the volume was normalized (see intensities) and the mask adapted to the NIfTI data (see blue overlay).}
                                    \label{preprocessing_xample}
                                \end{figure}
                            \end{myblock}\vfill





                        }

                    \end{minipage}
                \end{beamercolorbox}
            \end{column}
            \begin{column}{.59\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.95\textwidth} % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously


                            \begin{myblock}{Results}
                                We evaluate the effects of our classifier on a full-fledged registration workflow via the benchmarking algorithms from \cite{irsabi}.
                                Additionally, we show a qualitative comparison between data processed with our Masked workflow and data processed with the Generic workflow (\cref{reg_comp}).
                                \begin{figure}
                                    \centering
                                    \resizebox{0.85\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/reg_comp.py', data = '')}
                                    }
                                    \caption{
                                        \textbf{The masked workflow accurately transforms the image to the template space.}
                                        The comparison of the Generic (first row) and the Masked (second row) workflow shows that the Masked workflow accurately maps the brain region to the template and prevents the inclusion of non-brain voxels.
                                    }
                                    \label{reg_comp}
                                \end{figure}

%                                \begin{figure}
%%                                    \centering
%                                    \includegraphics[width=0.4\textwidth]{data/reg_comp}
%                                    \caption{\textbf{The masked workflow accurately transforms the image to the template space.} The comparison of the Generic (first row) and the Masked (second row) workflow shows that the masked workflow accurately maps the brain region to the template and prevents the inclusion of non-brain voxels.}
%                                    \label{reg_comp}
%                                \end{figure}

                                \begin{figure}
                                    \includegraphics[width=0.8\textwidth]{data/testset_examples_small}
                                    \caption{\textbf{The Classifier predicts a similar mask to the ground truth.}
                                    Randomly picked plots from the test set illustrate the predictions of the classifier (shown in red) in contrast to the template mask (shown in green).
                                    The overlap of the predicted mask and the template mask is shown in grey.}
                                \end{figure}


                                \begin{sansmath}
                                    \py{pytex_subfigs(
                                        [
                                            {'script':'scripts_/vcc_violin.py', 'label':'vccv','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.1em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the VCF across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/scf_violin_contrasts.py', 'label':'sccv','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.1em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the SCF across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/vc_violin_absdiff.py', 'label':'vcfb','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.5em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the distributions of the absolute VCF errors, across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/scf_violin_absdiff.py', 'label':'scfb','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.5em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the distributions of the absolute SCF errors, across workflows and functional contrasts.'
                                        ,},
                                        ],
                                        caption='\\textbf{Both the SAMRI Generic and the Masked workflow optimally and reliably conserve volume and smoothness, the latter showing values that are closely distributed to 1.}
                                        Plots showing the distribution of two target metrics in the first row, together with the respective distributions of the absolute distances to 1 in the second row. Dashed lines in the colored distribution densities indicate the sample mean and dashed lines the inner quartiles.
                                        ',
                                        label='fig:vc',
                                        environment='figure',
                                        )}
                                \end{sansmath}
                            \end{myblock}

                            \begin{myblock}{Results and Discussion}
                                \begin{itemize}
                                    \item Introducing \textcolor{lg}{MLEBE}-based brain extraction to the SAMRI workflow considerably improves registration accuracy --- with respect to volume conservation, smoothness conservation, and qualitative evaluation.
                                    \item The brain extraction classifier is trained with data that is preprocessed by the SAMRI Generic registration workflow such that large data collections can be leveraged with no manual labeling required.
                                    The classifier can thus be incrementally perfected with additional data that can be obtained via the novel SAMRI Masked workflow.
                                    \item The FOSS distribution model \cite{repsep} for the classifier, workflow, and the article, allows users to easily take advantage of the library and reexecure the steps described herein.
                                    \item We make all functions publicly available through the \textcolor{mg}{mlebe} Python package \cite{mlebe}, including those used for masking in the workflow and those used to train the classifier \cite{mlebe_trainingdata}.

                                \end{itemize}
                            \end{myblock}\vfill

                            \begin{myblock}{References}
                                \vspace{-1em}
                                \begin{multicols}{2}
                                    \scriptsize
                                    \bibliographystyle{ieeetr}
                                    \bibliography{./bib}
                                \end{multicols}
                                \vspace{-1em}
                            \end{myblock}\vfill


                        }
                    \end{minipage}
                \end{beamercolorbox}
            \end{column}

        \end{columns}
    \end{frame}
\end{document}
