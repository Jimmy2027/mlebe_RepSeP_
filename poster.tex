\input{poster/header.tex}

\title{Machine Learning Enabled Brain Segmentation for Small Animal Neuroimaging Registration}

\author{Hendrik J. Klug$^{1,6}$,Berkan Lafci$^{2,3,6}$,Zhiva Skachokova$^{6}$, Markus Rudin$^{4}$,Daniel Razansky$^{2,3}$, Horea-Ioan Ioanas$^{5,6}$}
\institute[ETH]{
    \small{
        $^{1}$ETHZ, Department of Information Technology and Electrical Engineering, Zurich, Switzerland\\
        $^{2}$UZH, Institute of Pharmacology and Toxicology and Institute for Biomedical Engineering, Faculty of Medicine, Zurich, Switzerland\\
        $^{3}$ETHZ, Institute for Biomedical Engineering, Department of Information Technology and Electrical Engineering, Zurich, Switzerland\\
        $^{4}$ETHZ, Center for Imaging Science and Technology, Zurich, Switzerland\\
        $^{5}$Massachusetts Institute of Technology, Department of Biological Engineering, Cambridge, United States of America\\
        $^{6}$Institute for Biomedical Engineering, D-ITET, ETH and University of Zurich, Switzerland
    }
}

\date{\today}

\newlength{\columnheight}
\setlength{\columnheight}{0.881\textheight}

\begin{document}
    \begin{frame}
        \vspace{2cm}
        \begin{columns}
            \begin{column}{.42\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.98\textwidth}  % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously
                            \begin{myblock}{Abstract}
                                \input{poster/abstract.tex}
                            \end{myblock}\vfill

                            \begin{myblock}{Objectives}
                                \begin{itemize}
                                    \item Develop a machine learning enabled brain extraction framework based on prior data from a non-masked registration workflow.
                                    \item Integrate this framework to a state-of-the-art small animal registration workflow from \cite{irsabi} and improve registration quality.
                                \end{itemize}
                            \end{myblock}

                            \begin{myblock}{Workflow integration}
                                We lay out a preparatory step to improve brain registration by specifically extracting the brain volume from the MRI scans (\cref{masked_worklfow_graph}).
                                \vspace{-1.4em}
                                \begin{figure}
                                    \centering
                                    \includedot[width=\textwidth]{data/poster/masked_nipype}
                                    \vspace{-2.9em}
                                    \caption{
                                        “SAMRI Generic Masked” workflow, which is based on the \textcolor{mg}{\texttt{antsRegistration}} function from \cite{irsabi}.\\
                                        Two additional nodes (shown in blue) provide the workflow with both the masked data and the binary mask.
                                    }
                                    \label{masked_worklfow_graph}
                                \end{figure}

                                \vspace{-1.5em}

                                \begin{figure}
                                    \centering
                                    \resizebox{0.9\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/masking_graph.py', data = '')}
                                    }
                                    \caption{The masking is performed with the \textcolor{lg}{MLEBE} \cite{mlebe} package which takes as input the unprocessed data and gives as output the masked data together with the binary mask. Both are used to restrict the computation of the transformation towards the reference space inside the brain area in the \textcolor{lg}{SAMRI} \cite{irsabi} package.}
                                \end{figure}
%%                                \vspace{-0.3em}
%                                \begin{figure}
%                                    \centering
%                                    \resizebox{0.4\textwidth}{!}{%
%                                        \py{pytex_printonly(script='scripts_/graphs/workflow_graph.py', data = '')}
%                                    }
%                                    \caption{Flowchart describing the integration of the \textcolor{lg}{MLEBE} \cite{mlebe} package into the \textcolor{lg}{SAMRI} \cite{noauthor_ibt-fmi/samri_2019} Generic workflow.}
%                                \end{figure}
                            \end{myblock}\vfill

%                            \vspace{-0.3em}
                            \begin{myblock}{Brain extraction framework}
                                \begin{itemize}
                                    \item The brain region extraction is done using a trained 3D U-Net \cite{ronneberger_u-net:_2015} which predicts a binary brain mask
                                    \item The training of the brain extraction classifier is done based on priors obtained by an unmasked workflow transformation from \textcolor{lg}{SAMRI} \cite{irsabi} to a template and using that template as ground truth for the training
                                    \item Some data optimization steps were added to create the training dataset:
                                    \begin{itemize}
                                        \item expert operators blacklisted incorrect annotations from the priors.
                                        \item the transformed data was normalized (by substracting the whole image mean and dividing by the standard deviation) (\cref{preprocessing_xample}).
                                        \item annotations extending beyond experimental data range were set to non-brain i.e. 0 (\cref{preprocessing_xample}).
                                        \item some random transformations were performed to augment the data such as rotations of up to 20$^{\circ}$, a random bias field added on the images and horizontal as well as vertical flips.

                                    \end{itemize}
                                \end{itemize}

                                \vspace{1em}

                                \begin{figure}
                                    \centering
                                    \resizebox{0.98\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/training_graph.py', data = '')}
                                    }
                                    \vspace{0.5em}
                                    \caption{Flowchart depicting the training process of the U-Net model. Outside the blue box are the processing steps that map the data to the template reference space. Inside the blue box are shown the training steps of the U-Net model. The model predicts a mask for each preprocessed input data which is then compared to the template mask using the Dice score. The parameters of the model are then updated such that the Dice score is maximized.}
                                    \label{training_graph}
                                \end{figure}

                                \begin{figure}
                                    \centering
                                    \begin{subfigure}{0.25\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/unpreprocessed}
                                    \end{subfigure}
                                    \hspace{2em}
                                    \begin{subfigure}{0.25\textwidth}
                                        \centering
                                        \includegraphics[width=\textwidth]{data/preprocessing_examples/preprocessed}
                                    \end{subfigure}
                                    \vspace{-0.5em}
                                    \caption{Comparison of an unprocessed slice (left) and a preprocessed slice (right) where the volume was normalized and the mask adapted to the nifty data.}
                                    \label{preprocessing_xample}
                                \end{figure}
                            \end{myblock}\vfill





                        }

                    \end{minipage}
                \end{beamercolorbox}
            \end{column}
            \begin{column}{.59\textwidth}
                \begin{beamercolorbox}[center]{postercolumn}
                    \begin{minipage}{.95\textwidth} % tweaks the width, makes a new \textwidth
                        \parbox[t][\columnheight]{\textwidth}{ % must be some better way to set the the height, width and textwidth simultaneously


                            \begin{myblock}{Results}
                                We evaluate the effects of our classifier on a full-fledged registration workflow via the benchmarking algorithms from \cite{irsabi}.
                                Additionally, we show a qualitative comparison between data processed with our Masked workflow and data processed with the Generic workflow in \cref{reg_comp}.
                                \begin{figure}
                                    \centering
                                    \resizebox{0.85\textwidth}{!}{%
                                        \py{pytex_printonly(script='scripts_/graphs/reg_comp.py', data = '')}
                                    }
                                    \caption{\textbf{The masked workflow accurately transforms the image to the template space.} The comparison of the Generic (first row) and the Masked (second row) workflow shows that the masked workflow accurately maps the brain region to the template and prevents the inclusion of non-brain voxels.}
                                    \label{reg_comp}
                                \end{figure}

%                                \begin{figure}
%%                                    \centering
%                                    \includegraphics[width=0.4\textwidth]{data/reg_comp}
%                                    \caption{\textbf{The masked workflow accurately transforms the image to the template space.} The comparison of the Generic (first row) and the Masked (second row) workflow shows that the masked workflow accurately maps the brain region to the template and prevents the inclusion of non-brain voxels.}
%                                    \label{reg_comp}
%                                \end{figure}

                                \begin{figure}
                                    \includegraphics[width=0.8\textwidth]{data/testset_examples_small}
                                    \caption{\textbf{The Classifier predicts a similar mask to the ground truth.}
                                    Randomly picked plots from the test set illustrate the predictions of the classifier (shown in red) in contrast to the template mask (shown in green).
                                    The overlap of the predicted mask and the template mask is shown in grey.}
                                \end{figure}


                                \begin{sansmath}
                                    \py{pytex_subfigs(
                                        [
                                            {'script':'scripts_/vcc_violin.py', 'label':'vccv','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.1em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the VCF across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/scf_violin_contrasts.py', 'label':'sccv','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.1em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the SCF across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/vc_violin_absdiff.py', 'label':'vcfb','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.5em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the distributions of the absolute VCF errors, across workflows and functional contrasts.'
                                        ,},
                                            {'script':'scripts_/scf_violin_absdiff.py', 'label':'scfb','conf':'poster/1col.conf', 'options_pre':'{.48\\textwidth}',
                                        'options_pre_caption':'\\vspace{-0.5em}\\',
                                        'options_post':'\\vspace{1em}',
                                        'caption':'Comparison of the distributions of the absolute SCF errors, across workflows and functional contrasts.'
                                        ,},
                                        ],
                                        caption='\\textbf{Both the SAMRI Generic and the Masked workflow optimally and reliably conserve volume and smoothness, the latter showing values that are closely distributed to 1.}
                                        Plots showing the distribution of two target metrics in the first row, together with the respective distributions of the absolute distances to 1 in the second row. Dashed lines in the colored distribution densities indicate the sample mean and dashed lines the inner quartiles.
                                        ',
                                        label='fig:vc',
                                        environment='figure',
                                        )}
                                \end{sansmath}
                            \end{myblock}

                            \begin{myblock}{Results and Discussion}
                                \begin{itemize}
                                    \item Adding a brain extraction step to the SAMRI workflow considerably improves registration accuracy as shown with volume conservation and smoothness conservation metrics as well as a qualitative evaluation.
                                    \item The brain extraction classifier is trained with data that is preprocessed with the SAMRI registration workflow such that no manual labeling is required.
                                    The classifier can thus be easily trained further with additional data that can be obtained via the novel SAMRI Masked workflow.
                                    \item The FOSS distribution model \cite{repsep} for both the classifier and workflow, as well as the article, allows users to easily take advantage of the classifier extendability and recreate the steps described herein.
                                    \item We make the functions publically available used for the masking in the workflow as well as those used to train the classifier, through the \textcolor{mg}{mlebe} Python package \cite{mlebe}.

                                \end{itemize}
                            \end{myblock}\vfill

                            \begin{myblock}{References}
                                \vspace{-1em}
                                \begin{multicols}{2}
                                    \scriptsize
                                    \bibliographystyle{ieeetr}
                                    \bibliography{./bib}
                                \end{multicols}
                                \vspace{-1em}
                            \end{myblock}\vfill


                        }
                    \end{minipage}
                \end{beamercolorbox}
            \end{column}

        \end{columns}
    \end{frame}
\end{document}
